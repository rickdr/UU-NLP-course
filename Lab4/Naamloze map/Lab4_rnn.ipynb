{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab4_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2yuDYEoSf29y",
        "GTEfoQ9bf294"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHUHsaYZf29e"
      },
      "source": [
        "# Lab 4: Recurrent models\n",
        "\n",
        "This lab gives you practice with embeddings (word vectors, in this case) and recurrent neural models in NLP. The first part focuses on embeddings as input to a recurrent model, and the second part focuses on embeddings derived from recurrent models, applying them to the task of word sense disambuiguation following the approach from the original paper by Peters et al.\n",
        "\n",
        "Everybody's machine is different and the neural computations required for this lab are more demanding than in the other assignments in this course. For this reason, it is advisable to use Google CoLab which guarantees a minimum level of performance. It is also recommended to use GPU acceleration; on CoLab, it can be turned on via <code>Runtime>Change Runtime type>GPU</code>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH8nlrr0adyB"
      },
      "source": [
        "## Part 1 (45 points)\n",
        "\n",
        "In the first part of lab 4, we will play with training a recurrent model for part of speech tagging. As an easy exercise, you will observe what happens when you plug in pretrained word embeddings into a neural NLP model and experiment with different sizes of training data.\n",
        "\n",
        "If you use Google Colab, it may be easiest to place this notebook and <code>lstm_tutorial.py</code> in <code>/Colab Notebooks</code> directory of your Google Drive. Run the code in the cell just below to enable CoLab to access the files on Drive. This will produce a link to an obscure redirect page which misleadingly suggests that you are getting Google Drive Desktop installation; what happens instead you are allowing the notebook running on Colab access to Drive. Copy the code that appears after you allow Drive access and paste it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMMvvupkmeAC"
      },
      "source": [
        "#RUN THIS CELL IF USING COLAB TO USE GOOGLE DRIVE FOR STORING lstm_tutorial.py AND/OR DATA FILES\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ1RsLnBqGzG"
      },
      "source": [
        "The neural network solutions in this lab rely on AllenNLP library version 0.9.0 (the other code of this lab assignment may work incorrectly with more recent versions); <code>overrides</code> is required for compatibility. Linguistic resources are from NLTK version 3.6.2 and might work incorrectly in other versions. Install these before proceeding; installation process may vary depending on your system. On CoLab, this can be done via the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3dSs1PCp4cH"
      },
      "source": [
        "#IF USING COLAB, INSTALL allennlp AND nltk AS FOLLOWS\n",
        "!pip install -U allennlp==0.9.0 overrides==3.1.0 nltk==3.6.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhqDZ2jqg6t2"
      },
      "source": [
        "**Before you start**,  import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veXo1-nEgRcM"
      },
      "source": [
        "import random\n",
        "import nltk\n",
        "import allennlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oS6ebmgXUE"
      },
      "source": [
        "If you run this for the first time, you may need to download various data using NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xazspBAgWsY"
      },
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('semcor')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSi4NJbvf29m"
      },
      "source": [
        "## Exercise 1: prepare the data (5 points)\n",
        "\n",
        "Linguistic data come in a variety of formats. You already had a chance to play with POS-annotated corpus data in Lab 1.\n",
        "\n",
        "In the first exercise, you will access POS-annotated data in one format (NLTK) and save it on the disk in a text format. Start with the tagged sentences from the Brown corpus, which can be retrieved as below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfRjmbgof29n",
        "outputId": "9800ec16-50b0-452d-ccf5-b136b4d5bf34"
      },
      "source": [
        "nltk.corpus.brown.tagged_sents()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sscz3p4Wf29o"
      },
      "source": [
        "Now randomize the order of all sentences in the corpus using <code>random.shuffle()</code> function and select the first 50K sentences for training and the next 5K for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ATjG29f29o"
      },
      "source": [
        "#Write your code here\n",
        "\n",
        "training_brown=\n",
        "validation_brown=\n",
        "testing_brown="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gUJh_0Cf29p"
      },
      "source": [
        "Define a function for saving your datasets to a text file in the following format:\n",
        "* one sentence per line\n",
        "* tokens separated by spaces\n",
        "* POS tag separated from the token by \"###\", for example <code>said###VBD</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkV4VOopf29p"
      },
      "source": [
        "def write_posdata(sentences,outfile):\n",
        "    #Write your code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCJDhupGf29p"
      },
      "source": [
        "Now save your data partitions in different sizes. We will start with small data samples since training on a large dataset may be very slow depending on your machine. We won't use the full 50K sentence training set in this lab since this might take too long."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHL8aS0Ff29q"
      },
      "source": [
        "write_posdata(training_brown,\"train_brown.txt\")\n",
        "write_posdata(validation_brown,\"validation_brown.txt\")\n",
        "write_posdata(training_brown[:50],\"train_brown_50.txt\")\n",
        "write_posdata(validation_brown[:50],\"validation_brown_50.txt\")\n",
        "write_posdata(training_brown[:500],\"train_brown_500.txt\")\n",
        "write_posdata(validation_brown[:500],\"validation_brown_500.txt\")\n",
        "write_posdata(training_brown[:5000],\"train_brown_5000.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc_zUrOFf29q"
      },
      "source": [
        "Congratulations, you have now saved the POS tagged data for model training purposes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "189kIzurf29q"
      },
      "source": [
        "## Exercise 2: train neural POS tagger models (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mptnxXdtf29q"
      },
      "source": [
        "We will now play with a neural model. You have installed <code>allennlp</code> which contains all necessary components for this and the training code for an LSTM model, which follows an old AllenNLP tutorial, is contained in <code>lstm_tutorial.py</code>. PLace the latter in the same directory as this notebook. Let us start by loading the model code and data, starting with a tiny sample for demonstration purposes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "259epBuCf29r"
      },
      "source": [
        "from lstm_tutorial import *\n",
        "\n",
        "train_dataset_tiny = reader.read(\"train_brown_50.txt\")\n",
        "validation_dataset_tiny = reader.read(\"validation_brown_50.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-sKAyIOf29r"
      },
      "source": [
        "Fist of all we need to initialize the vocabulary and define an embedding (vector) for each token. We set the embedding size at 300, common in realistic applications. By default, the embeddings are initialized randomly and updated during trining (this can be changed but we start with a standard configuration). We also need to specify the <code>HIDDEN_DIM</code> parameter: the dimensionality of the hidden vector representations in the LSTM cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs_TnMEVf29r"
      },
      "source": [
        "vocab_tiny = Vocabulary.from_instances(train_dataset_tiny + validation_dataset_tiny)\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 20\n",
        "\n",
        "token_embedding_tiny = Embedding(num_embeddings=vocab_tiny.get_vocab_size('tokens'),\n",
        "                            embedding_dim=EMBEDDING_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VBM__cvf29s"
      },
      "source": [
        "Download the smallest pretrained word vector model from https://nlp.stanford.edu/projects/glove/, unzip it, and extract the relevant file <code>'glove.6B.300d.txt'</code> in your working directory. The size of the file is 1GB; if using Google Drive with Colab, make sure you have sufficient space. Downloading and uploading the file might take a few minutes. You can <b>either</b> upload the relevant file from your personal machine `or` use the code below directly from CoLab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCwJNHW4f29s"
      },
      "source": [
        "#THIS CELL IS OPTIONAL, TO BE USED ON COLAB. YOU CAN USE wget AS BELOW OR ALTERNATIVELY UPLOAD GloVe EMBEDDINGS TO GOOGLE DRIVE FROM YOUR MACHINE\n",
        "# download the file\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# unzip the file\n",
        "!unzip -d . 'glove.6B.zip'\n",
        "# remove useless contents\n",
        "!rm 'glove.6B.200d.txt' 'glove.6B.100d.txt' 'glove.6B.50d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuyuEFT84I_L"
      },
      "source": [
        "Initialize token embeddings with values from pretrained GloVe model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZxCtoNx4JU4"
      },
      "source": [
        "glove_token_embedding_tiny = Embedding.from_params(vocab=vocab_tiny,\n",
        "                            params=Params({'pretrained_file':'glove.6B.300d.txt',\n",
        "                                           'embedding_dim' : EMBEDDING_DIM}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4fGrTT8f29s"
      },
      "source": [
        "Now from embedding a single word with <code>token_embedding_tiny</code> we can proceed to mapping a word sequence into a sequence of vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-uHqEoHf29s"
      },
      "source": [
        "word_embeddings_tiny = BasicTextFieldEmbedder({\"tokens\": token_embedding_tiny})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNOneYeuf29t"
      },
      "source": [
        "The following initializes parameters of an LSTM model using <code>word_embeddings_tiny</code> input encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QlU7YZyf29t"
      },
      "source": [
        "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
        "\n",
        "model_tiny = LstmTagger(word_embeddings_tiny, lstm, vocab_tiny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxSlztcf29t"
      },
      "source": [
        "Now define an LSTM model called <code>glove_model_tiny</code> that uses <code>glove_token_embedding_tiny</code>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArXUJdGDf29t"
      },
      "source": [
        "#write your code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r_aae7hf29u"
      },
      "source": [
        "Train the basic model for the tiny dataset. **Do not clear the output of this cell in the submitted version.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEZmbyDjf29u"
      },
      "source": [
        "basic_trainer_tiny=initialize_trainer(model_tiny,vocab_tiny,train_dataset_tiny,validation_dataset_tiny,batch_size=50)\n",
        "basic_trainer_tiny.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp-i19TIf29u"
      },
      "source": [
        "You have trained an LSTM POS tagger for the basic model. Now train the <code>glove_model_tiny</code>. **Do not clear the output of this cell in the submitted version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynwuhrTf29u"
      },
      "source": [
        "#Write your code here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6InZ96rBf29v"
      },
      "source": [
        "## Exercise 3: Explore training parameters (25 points)\n",
        "\n",
        "Create separate models on the basis of bigger datasets: the 500 sentence training and 500 sentence validation and 5000 sentence training and 5000 sentence validation. Using the full training set (50K sentences) is optional (your machine might be too slow). Initialize and train the basic model on 500 sentence training and 500 sentence validation data. **Do not clear the output of this cell in the submitted version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqdz7Ggxf29v"
      },
      "source": [
        "#train the basic model on 500 sentences\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0WNI4LYf29v"
      },
      "source": [
        "Now do the same training (500 sentence training and 500 sentence validation sets) with GloVE embeddings. **Do not clear the output of this cell in the submitted version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE4bNd6Nf29v"
      },
      "source": [
        "#write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtskLvp9f29v"
      },
      "source": [
        "Use a bigger training set now with 5K sentence training and 5K sentence validation sets and random initial embeddings. **Do not clear the output of this cell in the submitted version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptrXHJv2f29w"
      },
      "source": [
        "#write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIXSIJVAf29w"
      },
      "source": [
        "Now do the same training (5K sentence training and 5K sentence validation sets) with GloVE embeddings. **Do not clear the output of this cell in the submitted version.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmZUqY8Ef29w"
      },
      "source": [
        "#write your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE17T7irf29w"
      },
      "source": [
        "For each trained model, record validation accuracy and training duration (they are returned along with other training stats after training a model) and accuracy on the training set. Fill in the numbers in the table below:\n",
        "\n",
        "| model | validation accuracy | training accuracy | training duration|\n",
        "|-------|---------------------|---------------|-------------------------------------------\n",
        "| basic model on 50 sentences||||\n",
        "| glove model on 50 sentences||||\n",
        "| basic model on 500 sentences||||\n",
        "| glove model on 500 sentences||||\n",
        "| basic model on 5000 sentences||||\n",
        "| glove model on 5000 sentences||||\n",
        "\n",
        "**Question.** What do you conclude from these comparisons? when can it be especially beneficial to initialize a model with pretrained embeddings?\n",
        "\n",
        "**Answer.** WRITE YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yuDYEoSf29y"
      },
      "source": [
        "## Comment \n",
        "In this lab we used pretrained GloVe embeddings in a model for part of speech tagging. GloVe in its turn is also a neural word embedding model, but it had been trained on a completely different objective. GloVe vectors had been optimised on word cooccurrence matrix decomposition, i.e. on the task of predicting which words tend to occur with which other words. Part of speech certainly plays a role in determining statistical cooccurrence of words, but this role is indirect, and explicit part of speech information has not been used in training GloVe.\n",
        "\n",
        "This makes our application an example of **transfer learning**, whereby a learned model trained on one objective (e.g. word cooccurrence) can benefit a different application (e.g. POS tagging), because some information is shared between them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgQy4lRYf29y"
      },
      "source": [
        "## Part 2 - ELMo vectors (55 points)\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "In the second part of this lab we will reproduce the word sense disambiguation strategy that the authors of the ELMo vectors explored. The strategy consists in the following:\n",
        "\n",
        "- create ELMo embeddings for all tokens in a sense-annotated corpus\n",
        "- calculate mean sense vectors for each word sense in the training partition of the corpus\n",
        "- for each sense-annotated token in the test partition of the corpus, assign it to the sense of the word to which its ELMo vector is the closest according to the cosine distance metric\n",
        "- as a backup strategy, use the 1st sense of the word by default.\n",
        "\n",
        "As a sense annotated corpus, we can use SemCor, conveniently available within NLTK. <code>semcor.sents()</code> iterates over all sentences represented as lists of tokens, while <code>semcor.tagged_sents()</code> iterates over the same sentences with additional annotation including WordNet lemma identifiers (lemmas in WordNet stand for a word taken in a specific sense)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjzGDH1Ef29y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b8c76d-0606-41b9-9c57-70fa4dc7cdbc"
      },
      "source": [
        "from nltk.corpus import wordnet as wn  \n",
        "from nltk.corpus import semcor\n",
        "semcor.sents()\n",
        "semcor.tagged_sents(tag=\"sem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), Tree(Lemma('state.v.01.say'), ['said']), Tree(Lemma('friday.n.01.Friday'), ['Friday']), ['an'], Tree(Lemma('probe.n.01.investigation'), ['investigation']), ['of'], Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']), [\"'s\"], Tree(Lemma('late.s.03.recent'), ['recent']), Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']), Tree(Lemma('produce.v.04.produce'), ['produced']), ['``'], ['no'], Tree(Lemma('evidence.n.01.evidence'), ['evidence']), [\"''\"], ['that'], ['any'], Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']), Tree(Lemma('happen.v.01.take_place'), ['took', 'place']), ['.']], [['The'], Tree(Lemma('jury.n.01.jury'), ['jury']), Tree(Lemma('far.r.02.far'), ['further']), Tree(Lemma('state.v.01.say'), ['said']), ['in'], Tree(Lemma('term.n.02.term'), ['term']), Tree(Lemma('end.n.02.end'), ['end']), Tree(Lemma('presentment.n.01.presentment'), ['presentments']), ['that'], ['the'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['City', 'Executive', 'Committee'])]), [','], ['which'], Tree(Lemma('own.v.01.have'), ['had']), Tree(Lemma('overall.s.02.overall'), ['over-all']), Tree(Lemma('mission.n.03.charge'), ['charge']), ['of'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), [','], ['``'], Tree(Lemma('deserve.v.01.deserve'), ['deserves']), ['the'], Tree(Lemma('praise.n.01.praise'), ['praise']), ['and'], Tree(Lemma('thanks.n.01.thanks'), ['thanks']), ['of'], ['the'], Tree(Lemma('location.n.01.location'), [Tree('NE', ['City', 'of', 'Atlanta'])]), [\"''\"], ['for'], ['the'], Tree(Lemma('manner.n.01.manner'), ['manner']), ['in'], ['which'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), ['was'], Tree(Lemma('conduct.v.01.conduct'), ['conducted']), ['.']], ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xz-BK46f29z"
      },
      "source": [
        "## Exercise 1. Extract relevant data from SemCor (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugOwY0n5f29z"
      },
      "source": [
        "Let's prepare SemCor data for the disambiguation task. Since this is just an educational exercise and we don't aim at replicating the full results, we can use only a subset of SemCor. Take the first 10K sentences of SemCor and split them randomly into 90% training and 10% testing partitions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJxPaNl0f29z"
      },
      "source": [
        "#write your code here\n",
        "semcor_train=\n",
        "semcor_test="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCMYa2O6f29z"
      },
      "source": [
        "Create a function that takes as input a sentence from SemCor and extracts a list which contains, for each token of the sentence, either the corresponding WordNet Lemma (e.g. <code>Lemma('friday.n.01.Friday')</code>) or <code>None</code>. <code>None</code> corresponds to tokens that are either 1) not annotated for word senses (e.g. articles); 2) are marked up as (part of) a named entity (e.g. \"City of Atlanta\" or placename \"Fulton\" annotated as  <code>Tree(Lemma('location.n.01.location'), [Tree('NE', ['Fulton'])])</code>). For example, <code>get_lemmas</code> for the first sentence of Semcor should return <code>[None,\n",
        " None,\n",
        " None,\n",
        " None,\n",
        " None,\n",
        " Lemma('state.v.01.say'),\n",
        " Lemma('friday.n.01.Friday'),\n",
        " None,\n",
        " Lemma('probe.n.01.investigation'),\n",
        " None,\n",
        " Lemma('atlanta.n.01.Atlanta'),\n",
        " None,\n",
        " Lemma('late.s.03.recent'),\n",
        " Lemma('primary.n.01.primary_election'),\n",
        " Lemma('primary.n.01.primary_election'),\n",
        " Lemma('produce.v.04.produce'),\n",
        " None,\n",
        " None,\n",
        " Lemma('evidence.n.01.evidence'),\n",
        " None,\n",
        " None,\n",
        " None,\n",
        " Lemma('abnormality.n.04.irregularity'),\n",
        " Lemma('happen.v.01.take_place'),\n",
        " Lemma('happen.v.01.take_place'),\n",
        " None]</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIBT0eNff29z"
      },
      "source": [
        "def get_lemmas(semcor_sentence):\n",
        "    #your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JyNoPGWf290"
      },
      "source": [
        "You are now able to extract word senses (instantiated by WordNet lemmas) from the corpus. The next step is to associate senses with ELMo vectors. Create a dictionary of contextualized token embeddings from the training corpus grouped by the WordNet sense:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xboZFvxBf290"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "Train_embeddings=defaultdict(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmBr2DuTf290"
      },
      "source": [
        "Now let's create contextualized ELMo word embeddings for the tokens in this corpus. We can load the pretrained ELMo model and define a function <code>sentences_to_elmo()</code> that receives a list of tokenized sentences as input and produces their ELMo vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__NtRqd_f291"
      },
      "source": [
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "elmo = Elmo(options_file, weight_file, 1, dropout=0)\n",
        "\n",
        "def sentences_to_elmo(sentences):\n",
        "    character_ids = batch_to_ids(sentences)\n",
        "    embeddings = elmo(character_ids)\n",
        "    return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6COslg4f291"
      },
      "source": [
        "Now you can process the corpus sentences and produce their ELMo vectors. It is recommended to pass the input to ELMo encoder in batches. A suggested batch size is 50 sentences. For example, the code below processes the first 50 sentences from the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mdwEKBcf291"
      },
      "source": [
        "sentences=semcor.sents()[:50]\n",
        "\n",
        "embeddings=sentences_to_elmo(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMWX9iK3f291"
      },
      "source": [
        "The <code>embeddings</code> that we obtained is a dictionary that contains a list of ELMo embeddings and a list of masks. The mask tells us which embeddings correspond to tokens in the original input sentences and which correspond to the padding (introduced to give all sentences in the batch the same length).\n",
        "In principle all embeddings are stored in PyTorch tensors so that they can be used in bigger neural models, but we are not going to do it now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxl-DLl5f291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff312b3-ab54-4201-acea-d699b33c4a74"
      },
      "source": [
        "embeddings['elmo_representations'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2829,  0.2909, -0.0923,  ..., -0.2598, -0.2235, -0.2858],\n",
              "         [ 0.3223,  0.1005,  0.1432,  ...,  0.1395,  0.0625, -0.0712],\n",
              "         [ 0.2883, -0.1970,  0.1894,  ..., -0.4108,  0.2012, -0.2234],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.1808, -0.9733, -0.0844,  ..., -0.1500, -0.2365, -0.1484],\n",
              "         [ 0.0724, -0.6338, -0.3692,  ..., -0.2528,  0.2091, -0.2147],\n",
              "         [-0.4575, -0.3054,  0.0704,  ..., -0.8176,  1.0491, -0.1616],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.2887, -0.1648, -0.0569,  ..., -0.9878, -0.4030, -0.5798],\n",
              "         [ 0.4409, -0.3389, -0.7210,  ..., -0.2703, -0.2409, -0.6366],\n",
              "         [ 0.1121,  0.1720, -0.0230,  ..., -0.4125, -0.2054, -0.6982],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0518,  0.2389, -0.8026,  ..., -0.3444, -0.3708, -0.3733],\n",
              "         [ 0.2298, -0.0866,  0.5765,  ..., -0.1189,  0.0787, -0.4468],\n",
              "         [-0.3374, -0.2061, -0.1239,  ...,  0.0090,  0.8704, -0.3893],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[-0.8242, -0.1422, -0.2517,  ...,  0.4147,  0.2103, -0.2663],\n",
              "         [ 0.1398, -0.7132, -0.0675,  ...,  0.3322, -0.0435,  0.3761],\n",
              "         [-0.1739, -1.1644, -0.2469,  ...,  0.8304,  0.4397, -0.1567],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[-0.4803,  0.4749, -0.0254,  ..., -0.3872, -0.2686, -0.1806],\n",
              "         [ 0.0969, -0.1151,  0.1362,  ...,  0.4487,  0.0905, -0.6542],\n",
              "         [-0.1769,  0.2558, -0.5248,  ...,  0.2286,  0.4039, -0.2984],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5jIvP6f292"
      },
      "source": [
        "We can check the size of the embeddings we got. It has three dimensions: 1) the number of sentences 2) the number of tokens (corresponds to the tokens in the longest original sentence of the batch; shorter ones were padded) and 3) the dimensionality of the Elmo vector (1024)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCOUAg0xf292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa024d2f-1dc2-4bc9-d67f-bcf2cfbc4053"
      },
      "source": [
        "embeddings['elmo_representations'][0].detach().size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 58, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s0Uhdkef292"
      },
      "source": [
        "Another thing contained in the <code>embeddings</code> is the mask, a tensor encoding which token vectors correspond to original tokens and which are paddings. It has two dimensions, one corresponding to the sentences in the batch (50) and one corresponding to the token positions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMX0ix0mf292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fecaa8-a618-4541-c8a8-c1d20bf3c6ee"
      },
      "source": [
        "print(embeddings['mask'].size())\n",
        "embeddings['mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 59])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3czfz2Pbf292"
      },
      "source": [
        "## Exercise 2. Extract ELMo encoding of sentences using a mask (5 points)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-tHmhM_f293"
      },
      "source": [
        "Now define a function <code>get_masked_vectors(embeddings)</code> that takes embeddings as input and returns a list of ELMo sentence encodings to which the mask has been applied.  The output should be a list of Torch tensors, where the padding vectors have been removed so each sentence is represented by an nx1024 tensor where n is sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1AE4S7tf293"
      },
      "source": [
        "def get_masked_vectors(embeddings):\n",
        "    #Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruv6e7Khf293"
      },
      "source": [
        "## Exercise 3. Collect ELMo vectors from the training corpus (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBKWQadUf293"
      },
      "source": [
        "Process the corpus updating your train word sense vectors in the dictionary. Iterate over the all the train sentences in the corpus, and retrieve for each lemma-annotated token (where lemma is not <code>None</code>) the corresponding ELMo vector. Store the ELMo sense embeddings that correspond to each lemma in the dictionary <code>Train_embeddings</code>. This step of processing the training corpus with ELMo is the most time consuming part of this assignment. However, it should not take forever. If this computation takes more than an hour, you may want to optimize your code or make sure you are using GPU acceleration. For the purposes of developing and debugging your solution, you may start by use a sample of 100 sentences, but then switch to the full 9K sentence training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TDxnJP8f293"
      },
      "source": [
        "import torch\n",
        "#Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaYiHdKxl0Nj"
      },
      "source": [
        "How many senses does your Train_embeddings contain? **Do not clear the output of this cell in your submission**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8O6xolyl0_U"
      },
      "source": [
        "print(len(Train_embeddings))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2738_ZDJf293"
      },
      "source": [
        "## Exercise 4. Vector averaging (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17jEmM-Cf294"
      },
      "source": [
        "Your <code>Train_embeddings</code> now is a list of all vectors for a given word sense in the training corpus. For our purposes, we do not need the full list but the mean vector for each sense. For each sense in <code>Train_embeddings</code>, substitute the list by the average ELMo vector on the list. One efficient way to do this is to convert the list to a tensor via <code>stack</code> function and use Torch's <code>mean</code> function. Below is an example of how an average of two (random) vectors stored in a tensor can be computed in PyTorch: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ_hVCLLrMJj",
        "outputId": "2b0d2e7a-c372-4e8f-ec23-16caf33ba5a7"
      },
      "source": [
        " randtensor= torch.randn(2, 4)\n",
        " print(\"Tensor storing two 4-dimensional vectors:\\n\",randtensor)\n",
        " print(\"Average vector: \\n\",randtensor.mean(dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor storing two 4-dimensional vectors:\n",
            " tensor([[ 0.5662, -0.7278, -1.5063, -0.4371],\n",
            "        [ 0.5125,  0.0086,  0.9300,  1.4285]])\n",
            "Average vector: tensor([ 0.5394, -0.3596, -0.2882,  0.4957])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sr98O2_snqJ"
      },
      "source": [
        "Now you are ready to update your <code>Train_embeddings</code> so that it maps lemmas not to lists but to averaged vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tkldj34f294"
      },
      "source": [
        "#Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeP1NVl6f294"
      },
      "source": [
        "## Exercise 5. Testing the sense vectors (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hDY0vO4f294"
      },
      "source": [
        "Test your sense embeddings on your test data, which is a subset of the SemCor corpus. Use the strategy outlined above, with 1st WordNet sense as a fallback: \n",
        "\n",
        "- rely on mean sense vectors for each word sense in the training partition of the corpus, as stored in <code>Train_embeddings</code>\n",
        "- for each sense-annotated token <i>t</i> (e.g. the verb \"run\") in the test partition of the corpus, assign it to the sense of the word \"Lemma('X.v.n.run')\" to which ithe ELMo vector <i>t</i> is the closest according to the cosine distance metric\n",
        "- as a backup strategy, use the 1st sense of the word (e.g. <code>Lemma('run.n.01.run')</code>) from WordNet. You can look it up using a built-in function from NLTK (e.g. <code>wn.lemmas('run')</code>).\n",
        "\n",
        "Calculate WSD accuracy in percentage points on your test data. Report three numbers\n",
        "- overall accuracy (proportion of times the ELMo method+WordNet backup results in the correct sense annotation)\n",
        "- WordNet baseline accuracy: what if you always select the first WordNet sense, ignoring the ELMo embedding?\n",
        "- accuracy of the ELMo method just for the instances in which ELMo strategy is applicable\n",
        "- accuracy of the WordNet baseline just for the instances in which ELMo strategy is applicable\n",
        "\n",
        " **Do not delete the output of this cell in the submitted version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5etjZQfxf294"
      },
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "# Your code here\n",
        "print(\"Overall accuracy:\", accuracy) \n",
        "print(\"WordNet baseline:\", baseline_accuracy)\n",
        "print(\"Accuracy in cases where ELMo method is used\", elmo_accuracy)\n",
        "print(\"Accuracy of the baseline in cases where ELMo method is applicable\", baseline_on_elmo_data_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCwZotGaTvhX"
      },
      "source": [
        "If you reached this point, you were able to evaluate ELMo as a model of contextual semantic similarity of word usages. The idea behind the vector averaging is that a word when used in the same sense should have similar vector representations, while usages in distinct senses should have different vector representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYA5oaysEMz6"
      },
      "source": [
        "Analyze the numbers above. What do they tell you?\n",
        "\n",
        "**WRITE YOUR ANALYSIS HERE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTEfoQ9bf294"
      },
      "source": [
        "\n",
        "## The end\n",
        "Congratulations! this is the end of Lab 4."
      ]
    }
  ]
}